#################### Prompt Engineering ####################

'''''''''' Pillars of Prompt Engineering ''''''''''

1- Markdown 

Create login function with username and password

1.1 Markdown (standard)
1.2 XML
1.3 JSON

2- WSL (Windows Subsystem for Linux) 

For universal code development environment

3- AI CLI

Claude Code ($20 per month)
Codex CLI ($20 per month)
Gemini CLI (1000 requests free)
QWEN CLI (2000 requests free)

4- AI CLI's MCP Server

5- Test Driven Development Workflow

6- Spec Driven Development Define the steps for our business requirement

7- Deployment

Cluster: Group of computers
Digital Ocean
Azure

7.1 Docker
7.2 Kubernetes
7.3 Dapr
7.4 Ray (only for Linux)




#################### Prompt Engineering ####################

Prompt Engineering ka matlab hota hai AI (jaise ChatGPT) ko aise instructions ya questions dena jisse wo exact wohi jawab de jo hum chahte hain.
Matlab agar hum AI ko sahi aur smart tarike se samjha dein ke hume kis type ka answer chahiye — to wo zyada accurate, creative aur useful result dega.

#################### Prompt Engineering vs Context Engineering ####################

Prompt ka matlab hota hai apne LLM sy bat karna. Ya AI ko btana ky kia karna hai. 
To provide instruction to LLM. 


Context yani LLM ko information provide karna. Yani jo task karwana hai ous task sy related information provide karna.
To provide the background or relevant information to LLM.


#################### Understanding Large Language Models ####################

Large Language Model (LLM) ek aisa AI system hota hai jo human language ko samajh sakta hai, likh sakta hai aur uska matlab context ke sath samjhta hai.
Ye models — jaise ChatGPT, Claude, Gemini, Mistral — bohot massive data (internet text, books, code, etc.) par train hote hain.

'''''How LLMs Work (The Basics)'''''

Large Language Models are prediction engines that:

1- Take text input (your prompt)
2- Predict the next most likely word/token
3- Continue this process to generate complete responses
4- Base predictions on patterns learned from training data

'''''Key Concept: Autocompletion'''''

LLMs don't "understand" in the human sense—they're sophisticated autocomplete systems. Your prompt sets up the context for what should come next.

LLM hoty hain sophisticated autocomplete systems